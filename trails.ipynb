{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 10:53:27.410556: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-25 10:53:27.412432: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-25 10:53:27.443997: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-25 10:53:27.444785: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-25 10:53:28.052105: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import torchsummary\n",
    "from networks.att_squeeze_unet import AttentionBlock as AttentionBlockTF \n",
    "from networks.att_squeeze_unet_torch import AttentionBlock as AttentionBlockTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3.8535e-01, 2.4998e-01, 3.3459e-01,  ..., 1.9433e-01,\n",
       "           5.3380e-01, 2.7675e-01],\n",
       "          [2.8677e-01, 4.5784e-02, 8.8161e-02,  ..., 4.9397e-01,\n",
       "           8.5170e-02, 8.0231e-03],\n",
       "          [5.2116e-01, 2.2339e-02, 3.9514e-02,  ..., 3.6884e-01,\n",
       "           5.3792e-01, 4.3498e-02],\n",
       "          ...,\n",
       "          [3.7130e-01, 3.7697e-02, 2.2784e-01,  ..., 5.6777e-01,\n",
       "           2.2244e-01, 1.5534e-01],\n",
       "          [1.0200e-01, 1.5709e-01, 2.2349e-01,  ..., 5.2561e-01,\n",
       "           4.0734e-01, 4.6960e-01],\n",
       "          [1.2960e-01, 5.4038e-02, 1.8970e-01,  ..., 7.8393e-02,\n",
       "           1.0424e-01, 8.4386e-01]],\n",
       "\n",
       "         [[9.2958e-02, 3.5483e-01, 1.8347e-01,  ..., 1.7781e-01,\n",
       "           2.2970e-01, 3.6786e-01],\n",
       "          [2.5254e-01, 3.3351e-01, 3.5797e-02,  ..., 4.5837e-01,\n",
       "           2.3606e-01, 4.8517e-01],\n",
       "          [2.5652e-02, 6.8156e-02, 7.9543e-02,  ..., 1.2150e-01,\n",
       "           6.0057e-01, 1.6002e-01],\n",
       "          ...,\n",
       "          [4.6417e-01, 1.3726e-01, 2.8167e-01,  ..., 3.2678e-01,\n",
       "           1.1364e-01, 1.6955e-01],\n",
       "          [8.1421e-02, 2.4026e-01, 1.8891e-01,  ..., 3.7855e-01,\n",
       "           3.8153e-01, 2.5933e-01],\n",
       "          [3.0518e-01, 2.7136e-01, 3.6574e-02,  ..., 1.3256e-01,\n",
       "           4.5813e-02, 2.6887e-01]],\n",
       "\n",
       "         [[2.3929e-01, 2.7838e-01, 4.7720e-01,  ..., 3.5218e-01,\n",
       "           3.4092e-01, 2.9422e-01],\n",
       "          [1.2203e-01, 5.1286e-01, 7.9853e-01,  ..., 2.5623e-02,\n",
       "           1.3508e-01, 8.9104e-03],\n",
       "          [4.2832e-01, 2.3123e-01, 1.8877e-01,  ..., 6.1867e-01,\n",
       "           6.9678e-03, 2.1269e-01],\n",
       "          ...,\n",
       "          [2.9319e-01, 1.1756e-01, 1.2619e-01,  ..., 2.6065e-01,\n",
       "           1.9431e-01, 2.8741e-01],\n",
       "          [7.9435e-02, 2.2370e-02, 3.5564e-02,  ..., 3.6368e-01,\n",
       "           4.0222e-01, 6.6028e-02],\n",
       "          [4.2809e-01, 1.4714e-01, 5.0158e-02,  ..., 1.2764e-01,\n",
       "           4.7953e-01, 3.8543e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2.1423e-01, 1.5819e-01, 3.7667e-01,  ..., 1.3791e-02,\n",
       "           1.3567e-01, 3.3450e-01],\n",
       "          [3.2502e-01, 7.4226e-01, 3.9899e-01,  ..., 3.2206e-01,\n",
       "           2.1612e-01, 4.8266e-02],\n",
       "          [1.4809e-01, 1.4941e-01, 2.6587e-01,  ..., 4.0627e-01,\n",
       "           1.4965e-01, 2.4397e-02],\n",
       "          ...,\n",
       "          [5.9868e-04, 2.0631e-02, 2.7808e-01,  ..., 2.1822e-01,\n",
       "           3.1619e-01, 2.8423e-01],\n",
       "          [2.2839e-01, 3.0952e-01, 1.5351e-01,  ..., 1.1595e-01,\n",
       "           1.3793e-01, 6.3377e-01],\n",
       "          [5.0379e-01, 3.1893e-01, 2.4676e-01,  ..., 5.2232e-02,\n",
       "           3.6522e-01, 9.1302e-02]],\n",
       "\n",
       "         [[2.3332e-02, 3.0058e-01, 5.7789e-01,  ..., 1.6834e-01,\n",
       "           3.3954e-01, 1.6083e-01],\n",
       "          [2.2929e-01, 1.5872e-01, 6.6555e-01,  ..., 6.7066e-01,\n",
       "           1.0661e-01, 3.0489e-01],\n",
       "          [1.2228e-01, 2.1909e-01, 5.3342e-03,  ..., 1.7865e-02,\n",
       "           1.9304e-01, 2.5716e-01],\n",
       "          ...,\n",
       "          [5.0116e-01, 9.6233e-02, 2.4487e-02,  ..., 2.9730e-01,\n",
       "           2.1667e-02, 9.9039e-02],\n",
       "          [1.7425e-01, 2.9443e-01, 1.4145e-01,  ..., 3.5111e-01,\n",
       "           4.0985e-01, 5.9591e-01],\n",
       "          [1.4275e-01, 1.8501e-01, 4.2582e-02,  ..., 1.1068e-01,\n",
       "           9.2251e-03, 8.2646e-01]],\n",
       "\n",
       "         [[3.4811e-01, 5.5203e-01, 3.8544e-01,  ..., 1.3372e-01,\n",
       "           4.8347e-01, 1.4113e-01],\n",
       "          [9.9872e-02, 3.1421e-01, 2.0218e-01,  ..., 7.7492e-01,\n",
       "           1.7362e-01, 1.3076e-02],\n",
       "          [1.5771e-01, 1.5973e-02, 1.7844e-01,  ..., 5.8242e-01,\n",
       "           1.2032e-01, 1.5727e-02],\n",
       "          ...,\n",
       "          [1.4532e-01, 8.9307e-02, 6.8620e-01,  ..., 4.0895e-01,\n",
       "           2.8390e-01, 3.2511e-02],\n",
       "          [1.0578e-01, 1.4197e-01, 1.6289e-01,  ..., 6.9935e-02,\n",
       "           2.5515e-01, 4.1132e-01],\n",
       "          [4.5044e-01, 3.4002e-01, 1.1205e-01,  ..., 6.4703e-03,\n",
       "           4.2410e-01, 5.5275e-01]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_attention_block = AttentionBlockTF(32)\n",
    "random_input = tf.random.uniform((1, 256, 256, 32))\n",
    "random_input_1 = tf.random.uniform((1, 256, 256, 16))\n",
    "tf_attention_block(random_input_1, random_input)\n",
    "random_input_torch = torch.rand((1, 32, 256, 256))\n",
    "random_input_1_torch = torch.rand((1, 16, 256, 256))\n",
    "torch_attention_block = AttentionBlockTorch(32, 16, 32)\n",
    "torch_attention_block(random_input_torch, random_input_1_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 256, 256]              64\n",
      "       BatchNorm2d-2         [-1, 16, 256, 256]              32\n",
      "              ReLU-3         [-1, 16, 256, 256]               0\n",
      "            Conv2d-4         [-1, 64, 256, 256]           1,088\n",
      "              ReLU-5         [-1, 64, 256, 256]               0\n",
      "            Conv2d-6         [-1, 64, 256, 256]           9,280\n",
      "              ReLU-7         [-1, 64, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 10,464\n",
      "Trainable params: 10,464\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 152.00\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 152.79\n",
      "----------------------------------------------------------------\n",
      "(1, 256, 256, 128)\n",
      "Model: \"\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (1, 256, 256, 16)         128       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           multiple                  1088      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           multiple                  9280      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10496 (41.00 KB)\n",
      "Trainable params: 10464 (40.88 KB)\n",
      "Non-trainable params: 32 (128.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from networks.att_squeeze_unet import FireModule as FireModuleTF \n",
    "from networks.att_squeeze_unet_torch import FireModule as FireModuleTorch\n",
    "squeeze = 16\n",
    "expand = 64\n",
    "tf_fire_module = FireModuleTF(1, squeeze, expand)\n",
    "torch_fire_module = FireModuleTorch(1, squeeze, expand)\n",
    "random_input = tf.random.uniform((1, 256, 256, 3))\n",
    "random_input_torch = torch.rand((1, 3, 256, 256))\n",
    "torchsummary.summary(torch_fire_module, (3, 256, 256))\n",
    "tf_fire_module(random_input)\n",
    "tf_fire_module.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 96, 128, 128)\n",
      "(1, 96, 128, 128)\n",
      "(1, 48, 64, 256)\n",
      "(1, 48, 64, 256)\n",
      "(1, 24, 32, 384)\n",
      "(1, 24, 32, 384)\n",
      "(1, 24, 32, 512)\n",
      "(1, 24, 32, 512)\n",
      "(1, 24, 32, 384)\n",
      "(1, 24, 32, 256)\n",
      "(1, 48, 64, 128)\n",
      "(1, 96, 128, 64)\n",
      "Model: \"AttSqueezeUNet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             multiple                  1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  multiple                  0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  11472     \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  12496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  45472     \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  49568     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  105072    \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  111216    \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  189248    \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  197440    \n",
      "                                                                 \n",
      "  (UpsamplingBlock)          multiple                  1061524   \n",
      "                                                                 \n",
      "  (UpsamplingBlock)          multiple                  521316    \n",
      "                                                                 \n",
      "  (UpsamplingBlock)          multiple                  164260    \n",
      "                                                                 \n",
      "  (UpsamplingBlock)          multiple                  44120     \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2  multiple                  0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          multiple                  73792     \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSamplin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          multiple                  130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2588918 (9.88 MB)\n",
      "Trainable params: 2587326 (9.87 MB)\n",
      "Non-trainable params: 1592 (6.22 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_tf = AttSqueezeUNet(2,True)\n",
    "random_input_tf = tf.random.normal((1, 384, 512, 3))\n",
    "model_tf(random_input_tf)\n",
    "model_tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
