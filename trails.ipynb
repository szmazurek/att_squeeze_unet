{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 13:32:55.054894: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-25 13:32:55.056372: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-25 13:32:55.086405: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-25 13:32:55.087239: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-25 13:32:55.687165: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import torchsummary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tf x5 shape (1, 24, 32, 512)\n",
      "Tf x4 shape (1, 24, 32, 384)\n",
      "Tf d5 shape (1, 24, 32, 384)\n",
      "Tf d4 shape (1, 24, 32, 256)\n",
      "Tf d3 shape (1, 24, 32, 256)\n",
      "Tf x2 shape (1, 48, 64, 128)\n",
      "Tf d3 shape (1, 48, 64, 128)\n",
      "Tf d2 shape (1, 96, 128, 64)\n",
      "Tf d1 shape (1, 192, 256, 64)\n",
      "Model: \"AttSqueezeUNet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             multiple                  1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  multiple                  0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  11472     \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  12496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  45472     \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  49568     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  105072    \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  111216    \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  189248    \n",
      "                                                                 \n",
      "  (FireModule)               multiple                  197440    \n",
      "                                                                 \n",
      "  (UpsamplingBlock)          multiple                  1061524   \n",
      "                                                                 \n",
      "  (UpsamplingBlock)          multiple                  521316    \n",
      "                                                                 \n",
      "  (UpsamplingBlock)          multiple                  164260    \n",
      "                                                                 \n",
      "  (UpsamplingBlock)          multiple                  44120     \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2  multiple                  0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          multiple                  73792     \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSamplin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          multiple                  130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2588918 (9.88 MB)\n",
      "Trainable params: 2587326 (9.87 MB)\n",
      "Non-trainable params: 1592 (6.22 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from networks.att_squeeze_unet import AttSqueezeUNet as AttSqueezeUNetTF\n",
    "model_tf = AttSqueezeUNetTF(2,True)\n",
    "random_input_tf = tf.random.normal((1, 384, 512, 3))\n",
    "model_tf(random_input_tf)\n",
    "model_tf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf d3 shape (1, 24, 32, 256)\n",
    "Tf x2 shape (1, 48, 64, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 64, 128)\n",
      "Upconv in shape torch.Size([1, 512, 24, 32])\n",
      "Upconv shape torch.Size([1, 64, 48, 64])\n",
      "Attention shape torch.Size([1, 384, 48, 64])\n",
      "Upconv in shape torch.Size([1, 512, 24, 32])\n",
      "Upconv shape torch.Size([1, 64, 48, 64])\n",
      "Attention shape torch.Size([1, 384, 48, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 48, 64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from networks.att_squeeze_unet import UpsamplingBlock as UpsamplingBlockTF\n",
    "from networks.att_squeeze_unet_torch import UpsamplingBlock as UpsamplingBlockTorch\n",
    "from torch import nn\n",
    "tf_upsampling_block = UpsamplingBlockTF(\n",
    "            filters=64,\n",
    "            fire_id=11,\n",
    "            squeeze=16,\n",
    "            expand=64,\n",
    "            strides=(2, 2),\n",
    "            deconv_ksize=3,\n",
    "            att_filters=16,\n",
    "        )\n",
    "random_input_x = tf.random.uniform((1, 24, 32, 256))\n",
    "random_input_g = tf.random.uniform((1, 48, 64, 128))\n",
    "print(tf_upsampling_block(random_input_x, random_input_g).shape)\n",
    "random_input_x_torch = torch.rand((1, 512, 24, 32))\n",
    "random_input_g_torch = torch.rand((1, 384, 48, 64))\n",
    "torch_upsampling_block = UpsamplingBlockTorch(\n",
    "    filters=64,\n",
    "    fire_id=9,\n",
    "    squeeze=16,\n",
    "    expand=64,\n",
    "    deconv_ksize=3,\n",
    "    strides=(2, 2),\n",
    "    att_filters=16,\n",
    "    x_input_shape=random_input_x_torch.shape,\n",
    "    g_input_shape=random_input_g_torch.shape,\n",
    "    )\n",
    "\n",
    "torch_upsampling_block(random_input_x_torch, random_input_g_torch).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 71, 95])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upconv = nn.ConvTranspose2d(\n",
    "            in_channels=random_input_x_torch.shape[1],\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            stride=(2,2),\n",
    "            padding=(1, 1),\n",
    "            # output_padding=(1, 1),\n",
    "        )\n",
    "upconv(random_input_x_torch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 48, 64, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tf_upsampling_block.upconv(random_input_x)\n",
    "from matplotlib import pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.att_squeeze_unet import AttentionBlock as AttentionBlockTF \n",
    "from networks.att_squeeze_unet_torch import AttentionBlock as AttentionBlockTorch\n",
    "tf_attention_block = AttentionBlockTF(32)\n",
    "random_input = tf.random.uniform((1, 256, 256, 32))\n",
    "random_input_1 = tf.random.uniform((1, 256, 256, 16))\n",
    "tf_attention_block(random_input_1, random_input)\n",
    "random_input_torch = torch.rand((1, 32, 256, 256))\n",
    "random_input_1_torch = torch.rand((1, 16, 256, 256))\n",
    "torch_attention_block = AttentionBlockTorch(32, 16, 32)\n",
    "torch_attention_block(random_input_torch, random_input_1_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.att_squeeze_unet import FireModule as FireModuleTF \n",
    "from networks.att_squeeze_unet_torch import FireModule as FireModuleTorch\n",
    "squeeze = 16\n",
    "expand = 64\n",
    "tf_fire_module = FireModuleTF(1, squeeze, expand)\n",
    "torch_fire_module = FireModuleTorch(1, squeeze, expand)\n",
    "random_input = tf.random.uniform((1, 256, 256, 3))\n",
    "random_input_torch = torch.rand((1, 3, 256, 256))\n",
    "torchsummary.summary(torch_fire_module, (3, 256, 256))\n",
    "tf_fire_module(random_input)\n",
    "tf_fire_module.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
